{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2d39ec-fec3-4fcc-9689-cd37ab3fabb3",
   "metadata": {},
   "source": [
    "This script is built to run in python 3.13\n",
    "Matching script\n",
    "‚úÖMatch the experimental spectra to the in-silico generated spectra (1: m, one to many matching)\n",
    "‚úÖScore every pair using cosine similarity\n",
    "‚úÖApply dual mass tolerance window to accommodate for the higher mass error (10 ppm) in fragments below 100 Da, while 5 ppm is selected for higher masses\n",
    "‚úÖRemove peaks matching the precursor m/z within 10 ppm were excluded from similarity scoring to avoid false positives\n",
    "‚úÖKeep only hits above threshold (e.g. > 0.5)\n",
    "‚úÖOutput results to CSV for inspection & prioritization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828c837-4a2e-4101-89ba-f5d0a65a993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.importing import load_from_msp\n",
    "from matchms.similarity import CosineGreedy\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e902bd-cfcc-4b0f-b32f-f0bdd470e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === File paths ===\n",
    "exp_file = \"Extracted_MS2_Spectra_PosMode.msp\"\n",
    "cfmid_file = \"cfmid_combined_all_energies.msp\"\n",
    "output_csv = \"Spectral_Matches_PosMode_vs_online_predicted_allenergies.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4159f8-75aa-4144-be9e-84551228f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === File paths NI ===\n",
    "#exp_file = \"Extracted_MS2_Spectra_NegMode.msp\"\n",
    "#cfmid_file = \"cfmid_predicted_NI_20eV.msp\"\n",
    "#output_csv = \"Spectral_Matches_NegMode_NI_20eV.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7697540b-724e-45c2-8eb1-71d70c7ad8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load spectra ===\n",
    "experimental = list(load_from_msp(exp_file))\n",
    "predicted = list(load_from_msp(cfmid_file))\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(experimental)} experimental and {len(predicted)} predicted spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55347f71-7cd3-4a5d-a178-8833889cab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_ppm(spec1, spec2, ppm_tol=5, ppm_tol_low=10, mz_cutoff=100):\n",
    "    mz1, intens1 = np.array(spec1.mz), np.array(spec1.intensities)\n",
    "    mz2, intens2 = np.array(spec2.mz), np.array(spec2.intensities)\n",
    "    precursor1 = spec1.get(\"precursor_mz\")\n",
    "    precursor2 = spec2.get(\"precursor_mz\")\n",
    "    precursor_tol = 10  # ppm window around precursor to ignore\n",
    "\n",
    "    # Normalize intensities\n",
    "    intens1 = intens1 / intens1.max() if intens1.max() > 0 else intens1\n",
    "    intens2 = intens2 / intens2.max() if intens2.max() > 0 else intens2\n",
    "\n",
    "    # Sort m/z arrays\n",
    "    i, j = 0, 0\n",
    "    matched1, matched2 = [], []\n",
    "\n",
    "    while i < len(mz1) and j < len(mz2):\n",
    "        mz_val = mz1[i]\n",
    "        current_tol = ppm_tol_low if mz_val < mz_cutoff else ppm_tol\n",
    "        ppm_diff = abs(mz_val - mz2[j]) / mz_val * 1e6\n",
    "\n",
    "        if ppm_diff <= current_tol:\n",
    "            precursor_hit1 = abs(mz1[i] - precursor1) / precursor1 * 1e6 <= precursor_tol if precursor1 else False\n",
    "            precursor_hit2 = abs(mz2[j] - precursor1) / precursor1 * 1e6 <= precursor_tol if precursor1 else False\n",
    "            if precursor_hit1 or precursor_hit2:\n",
    "                i += 1\n",
    "                j += 1\n",
    "                continue  # skip precursor ion\n",
    "            matched1.append(intens1[i])\n",
    "            matched2.append(intens2[j])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif mz1[i] < mz2[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "    if len(matched1) == 0:\n",
    "        return 0.0, 0\n",
    "\n",
    "    dot = np.dot(matched1, matched2)\n",
    "    norm1 = np.linalg.norm(matched1)\n",
    "    norm2 = np.linalg.norm(matched2)\n",
    "    cosine_score = dot / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0.0\n",
    "\n",
    "    return cosine_score, len(matched1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af709db-7f7e-471d-87e9-2737eee0d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Match spectra using PPM-based cosine ===\n",
    "precursor_ppm = 5  # stricter precursor filter\n",
    "fragment_ppm = 5  # used in the cosine similarity function\n",
    "ppm_tol_low=10  # for fragments < 100 m/z\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp_spec in experimental:\n",
    "    mz_exp = exp_spec.get(\"precursor_mz\")\n",
    "    if mz_exp is None:\n",
    "        continue\n",
    "\n",
    "    for pred_spec in predicted:\n",
    "        mz_pred = pred_spec.get(\"precursor_mz\")\n",
    "        if mz_pred is None:\n",
    "            continue\n",
    "\n",
    "        # Step 1: precursor filter\n",
    "        ppm_diff = abs(mz_exp - mz_pred) / mz_exp * 1e6\n",
    "        if ppm_diff > precursor_ppm:\n",
    "            continue\n",
    "\n",
    "        # Step 2: compare fragments using cosine with ppm tolerance\n",
    "        score, n_matches = cosine_similarity_ppm(exp_spec, pred_spec, ppm_tol=fragment_ppm)\n",
    "        if score > 0.5:\n",
    "            results.append({\n",
    "                \"Feature_ID\": exp_spec.get(\"feature_id\"),\n",
    "                \"Experimental_mz\": mz_exp,\n",
    "                \"RT_min\": exp_spec.get(\"retention_time\"),\n",
    "                \"Predicted_Name\": pred_spec.get(\"name\") or pred_spec.get(\"compound_name\"),\n",
    "                \"Predicted_mz\": mz_pred,\n",
    "                \"SMILES\": pred_spec.get(\"smiles\"),\n",
    "                \"Cosine_Score\": round(score, 4),\n",
    "                \"Num_Matching_Peaks\": n_matches\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a12be-d40b-4889-83fc-40765bcb2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save to CSV ===\n",
    "df = pd.DataFrame(results)\n",
    "df.sort_values(\"Cosine_Score\", ascending=False, inplace=True)\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"‚úÖ Done! Found {len(df)} matches with cosine > 0.5 at {precursor_ppm} ppm tolerance\")\n",
    "print(f\"üìÅ Results saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91790731-ba4c-41fa-bcc7-4da284d5c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Keep only the best match per Feature_ID based on NUM_MATCHING_PEAKS ===\n",
    "best_matches_df_online = df.sort_values(\"Num_Matching_Peaks\", ascending=False).drop_duplicates(\"Feature_ID\")\n",
    "\n",
    "# Secondary sort by cosine score\n",
    "best_matches_df_online = best_matches_df_online.sort_values([\"Num_Matching_Peaks\", \"Cosine_Score\"], ascending=[False, False])\n",
    "\n",
    "# ‚ùå Remove meaningless perfect matches with only 1 peak\n",
    "best_matches_df_online = best_matches_df_online[\n",
    "    ~((best_matches_df_online[\"Num_Matching_Peaks\"] == 1) & (best_matches_df_online[\"Cosine_Score\"] == 1.0))\n",
    "]\n",
    "\n",
    "# üßπ Remove duplicate predicted compounds\n",
    "best_matches_df_online = best_matches_df_online.drop_duplicates(subset=\"Predicted_Name\", keep=\"first\")\n",
    "\n",
    "# üíæ Save to CSV\n",
    "best_matches_df_online.to_csv(\"Top_Matches_By_NumPeaks_PosMode_ppm5_online.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Final curated matches: {len(best_matches_df_online)} unique features + predicted compounds retained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae030703-5e8f-4ad1-80d3-e09332109230",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Next step is Retip, which I will be running in R. \n",
    "#Retip needs training set with known compounds and their respective Rt to create the model and the suspect screening results to predict the rt based on the proposed structure\n",
    "#Prepare the data for Retip as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2b73c-d9b7-402d-aa46-4531ffa09731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load files ===\n",
    "matches_file = \"Top_Matches_By_NumPeaks_PosMode_ppm5_online.csv\"\n",
    "cfmid_file = \"Matched_Suspects_PositiveMode_with_CFMID_ID.csv\"\n",
    "\n",
    "matches_df = pd.read_csv(matches_file)\n",
    "cfmid_df = pd.read_csv(cfmid_file)\n",
    "\n",
    "# === Standardize key columns ===\n",
    "cfmid_df[\"CFMID_ID\"] = cfmid_df[\"CFMID_ID\"].astype(str).str.strip()\n",
    "matches_df[\"Predicted_Name\"] = matches_df[\"Predicted_Name\"].astype(str).str.strip()\n",
    "\n",
    "# === Merge on CFMID ID ===\n",
    "merged = matches_df.merge(\n",
    "    cfmid_df[[\"CFMID_ID\", \"Canonical_SMILES\"]],\n",
    "    left_on=\"Predicted_Name\",\n",
    "    right_on=\"CFMID_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Optional: move Canonical_SMILES column next to SMILES for clarity\n",
    "cols = list(merged.columns)\n",
    "if \"SMILES\" in cols and \"Canonical_SMILES\" in cols:\n",
    "    smi_idx = cols.index(\"SMILES\")\n",
    "    cols.insert(smi_idx + 1, cols.pop(cols.index(\"Canonical_SMILES\")))\n",
    "    merged = merged[cols]\n",
    "\n",
    "# === Save result ===\n",
    "merged.to_csv(\"Top_Matches_Annotated_PosMode.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Done! Canonical SMILES added. Final shape: {merged.shape}\")\n",
    "print(\"üìÅ Saved to: Top_Matches_Annotated_PosMode.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e36376-04a4-4633-9e79-7c1160a6c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotated matches\n",
    "df = pd.read_csv(\"Top_Matches_Annotated_PosMode.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    \"Predicted_Name\", \"Predicted_mz\", \"SMILES\", \"Cosine_Score\", \"Num_Matching_Peaks\"\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Rename Canonical_SMILES ‚Üí smiles\n",
    "df = df.rename(columns={\"Canonical_SMILES\": \"SMILES\"})\n",
    "\n",
    "# Save to new CSV\n",
    "df.to_csv(\"suspect_for_retip_online.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved suspect list for Retip prediction: {df.shape[0]} entries\")\n",
    "print(\"üìÅ File: suspect_for_retip_online.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb1d38-1d72-4bbb-9a29-824ed32dc1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move to RStudio to predict retention times. Bring back a csv files containing only the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d85c4-5449-4d6b-904d-03f56c47683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the files\n",
    "top_matches = pd.read_csv(\"Top_Matches_Annotated_PosMode.csv\")\n",
    "rt_outliers = pd.read_csv(\"RT_Outliers_XGB_online.csv\")\n",
    "\n",
    "# Remove outliers based on Feature_ID\n",
    "filtered = top_matches[~top_matches[\"Feature_ID\"].isin(rt_outliers[\"Feature_ID\"])]\n",
    "\n",
    "# Save the filtered result\n",
    "filtered.to_csv(\"Top_Matches_Annotated_PosMode_filtered.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Filtered matches saved ‚Äî {len(filtered)} entries remaining after removing RT outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d2e9f-6d66-41cc-a3f8-42f7b0965fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all info \n",
    "# Load data\n",
    "filtered_matches = pd.read_csv(\"Top_Matches_Annotated_PosMode_filtered.csv\")\n",
    "meta = pd.read_csv(\"Matched_Suspects_PositiveMode_with_CFMID_ID.csv\", dtype=str)\n",
    "\n",
    "# Merge desired metadata fields\n",
    "merged = pd.merge(\n",
    "    filtered_matches,\n",
    "    meta[[\"CFMID_ID\", \"Suspect Name\", \"Function\", \"Source\", \"Formula\"]],\n",
    "    on=\"CFMID_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Save the enriched result\n",
    "merged.to_csv(\"Top_Matches_Annotated_PosMode_filtered_enriched.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Enriched matches saved ‚Äî {len(merged)} entries with additional suspect metadata.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3514d5df-cbc5-470a-bd60-7900eea3fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === File paths NI ===\n",
    "exp_file = \"Extracted_MS2_Spectra_NegMode.msp\"\n",
    "cfmid_file = \"cfmid_predicted_NI_20eV.msp\"\n",
    "output_csv = \"Spectral_Matches_NegMode_NI_20eV.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a870f-145f-430b-92ef-00c52554b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load spectra ===\n",
    "experimental = list(load_from_msp(exp_file))\n",
    "predicted = list(load_from_msp(cfmid_file))\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(experimental)} experimental and {len(predicted)} predicted spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a066ad-8ff6-4520-9359-380ba7cb3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Match spectra using PPM-based cosine ===\n",
    "precursor_ppm = 5  # stricter precursor filter\n",
    "fragment_ppm = 5  # used in the cosine similarity function\n",
    "ppm_tol_low=10  # for fragments < 100 m/z\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp_spec in experimental:\n",
    "    mz_exp = exp_spec.get(\"precursor_mz\")\n",
    "    if mz_exp is None:\n",
    "        continue\n",
    "\n",
    "    for pred_spec in predicted:\n",
    "        mz_pred = pred_spec.get(\"precursor_mz\")\n",
    "        if mz_pred is None:\n",
    "            continue\n",
    "\n",
    "        # Step 1: precursor filter\n",
    "        ppm_diff = abs(mz_exp - mz_pred) / mz_exp * 1e6\n",
    "        if ppm_diff > precursor_ppm:\n",
    "            continue\n",
    "\n",
    "        # Step 2: compare fragments using cosine with ppm tolerance\n",
    "        score, n_matches = cosine_similarity_ppm(exp_spec, pred_spec, ppm_tol=fragment_ppm)\n",
    "        if score > 0.5:\n",
    "            results.append({\n",
    "                \"Feature_ID\": exp_spec.get(\"feature_id\"),\n",
    "                \"Experimental_mz\": mz_exp,\n",
    "                \"RT_min\": exp_spec.get(\"retention_time\"),\n",
    "                \"Predicted_Name\": pred_spec.get(\"name\") or pred_spec.get(\"compound_name\"),\n",
    "                \"Predicted_mz\": mz_pred,\n",
    "                \"SMILES\": pred_spec.get(\"smiles\"),\n",
    "                \"Cosine_Score\": round(score, 4),\n",
    "                \"Num_Matching_Peaks\": n_matches\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8627d6c-6cbf-4ff7-9a4c-a010aa6bc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save to CSV ===\n",
    "df = pd.DataFrame(results)\n",
    "df.sort_values(\"Cosine_Score\", ascending=False, inplace=True)\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"‚úÖ Done! Found {len(df)} matches with cosine > 0.5 at {precursor_ppm} ppm tolerance\")\n",
    "print(f\"üìÅ Results saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87665f14-f076-49b0-bbf2-bcf61988426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Keep only the best match per Feature_ID based on NUM_MATCHING_PEAKS ===\n",
    "best_matches_df_online = df.sort_values(\"Num_Matching_Peaks\", ascending=False).drop_duplicates(\"Feature_ID\")\n",
    "\n",
    "# Secondary sort by cosine score\n",
    "best_matches_df_online = best_matches_df_online.sort_values([\"Num_Matching_Peaks\", \"Cosine_Score\"], ascending=[False, False])\n",
    "\n",
    "# ‚ùå Remove meaningless perfect matches with only 1 peak\n",
    "best_matches_df_online = best_matches_df_online[\n",
    "    ~((best_matches_df_online[\"Num_Matching_Peaks\"] == 1) & (best_matches_df_online[\"Cosine_Score\"] == 1.0))\n",
    "]\n",
    "\n",
    "# üßπ Remove duplicate predicted compounds\n",
    "best_matches_df_online = best_matches_df_online.drop_duplicates(subset=\"Predicted_Name\", keep=\"first\")\n",
    "\n",
    "# üíæ Save to CSV\n",
    "best_matches_df_online.to_csv(\"Top_Matches_By_NumPeaks_NegMode_ppm5.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Final curated matches: {len(best_matches_df_online)} unique features + predicted compounds retained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72eb18-caf6-4e21-8fe5-ea653c41a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load files ===\n",
    "matches_file = \"Top_Matches_By_NumPeaks_NegMode_ppm5.csv\"\n",
    "cfmid_file = \"Matched_Suspects_NegativeMode_with_CFMID_ID.csv\"\n",
    "\n",
    "matches_df = pd.read_csv(matches_file)\n",
    "cfmid_df = pd.read_csv(cfmid_file)\n",
    "\n",
    "# === Standardize key columns ===\n",
    "cfmid_df[\"CFMID_ID\"] = cfmid_df[\"CFMID_ID\"].astype(str).str.strip()\n",
    "matches_df[\"Predicted_Name\"] = matches_df[\"Predicted_Name\"].astype(str).str.strip()\n",
    "\n",
    "# === Merge on CFMID ID ===\n",
    "merged = matches_df.merge(\n",
    "    cfmid_df[[\"CFMID_ID\", \"Canonical_SMILES\"]],\n",
    "    left_on=\"Predicted_Name\",\n",
    "    right_on=\"CFMID_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Optional: move Canonical_SMILES column next to SMILES for clarity\n",
    "cols = list(merged.columns)\n",
    "if \"SMILES\" in cols and \"Canonical_SMILES\" in cols:\n",
    "    smi_idx = cols.index(\"SMILES\")\n",
    "    cols.insert(smi_idx + 1, cols.pop(cols.index(\"Canonical_SMILES\")))\n",
    "    merged = merged[cols]\n",
    "\n",
    "# === Save result ===\n",
    "merged.to_csv(\"Top_Matches_Annotated_NegMode.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Done! Canonical SMILES added. Final shape: {merged.shape}\")\n",
    "print(\"üìÅ Saved to: Top_Matches_Annotated_NegMode.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8f1a0-735b-470e-aef6-afdc9a6a921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotated matches\n",
    "df = pd.read_csv(\"Top_Matches_Annotated_NegMode.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    \"Predicted_Name\", \"Predicted_mz\", \"SMILES\", \"Cosine_Score\", \"Num_Matching_Peaks\"\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Rename Canonical_SMILES ‚Üí smiles\n",
    "df = df.rename(columns={\"Canonical_SMILES\": \"SMILES\"})\n",
    "\n",
    "# Save to new CSV\n",
    "df.to_csv(\"suspect_for_retip_NI.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved suspect list for Retip prediction: {df.shape[0]} entries\")\n",
    "print(\"üìÅ File: suspect_for_retip_NI.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a73a8-966f-4a36-84e1-cf6b62795c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the files\n",
    "top_matches = pd.read_csv(\"Top_Matches_Annotated_NegMode.csv\")\n",
    "rt_outliers = pd.read_csv(\"RT_Outliers_XGB_NI.csv\")\n",
    "\n",
    "# Remove outliers based on Feature_ID\n",
    "filtered = top_matches[~top_matches[\"Feature_ID\"].isin(rt_outliers[\"Feature_ID\"])]\n",
    "\n",
    "# Save the filtered result\n",
    "filtered.to_csv(\"Top_Matches_Annotated_NegMode_filtered.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Filtered matches saved ‚Äî {len(filtered)} entries remaining after removing RT outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41640daa-fee7-48d8-b80a-44999ecff073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all info \n",
    "# Load data\n",
    "filtered_matches = pd.read_csv(\"Top_Matches_Annotated_NegMode_filtered.csv\")\n",
    "meta = pd.read_csv(\"Matched_Suspects_NegativeMode_with_CFMID_ID.csv\", dtype=str)\n",
    "\n",
    "# Merge desired metadata fields\n",
    "merged = pd.merge(\n",
    "    filtered_matches,\n",
    "    meta[[\"CFMID_ID\", \"Suspect Name\", \"Function\", \"Source\", \"Formula\"]],\n",
    "    on=\"CFMID_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Save the enriched result\n",
    "merged.to_csv(\"Top_Matches_Annotated_NegMode_filtered_enriched.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Enriched matches saved ‚Äî {len(merged)} entries with additional suspect metadata.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833adfa4-00b4-4576-91ed-e1e9622f5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load the confirmed isotopic profile data ===\n",
    "confirmed_df = pd.read_excel(\"NIAS_2b_IP_confirmed.xlsx\")\n",
    "confirmed_ids = confirmed_df[\"ID\"].astype(str).tolist()  # Ensure IDs are strings for comparison\n",
    "\n",
    "# === Load the positive and negative mode match files ===\n",
    "pos_df = pd.read_csv(\"Top_Matches_Annotated_PosMode_filtered_enriched_deduplicated_ToxTree.csv\", dtype=str)\n",
    "neg_df = pd.read_csv(\"Top_Matches_Annotated_NegMode_filtered_enriched_deduplicated_ToxTree.csv\", dtype=str)\n",
    "\n",
    "# === Filter both DataFrames based on confirmed IDs ===\n",
    "filtered_pos = pos_df[pos_df[\"Feature_ID\"].isin(confirmed_ids)]\n",
    "filtered_neg = neg_df[neg_df[\"Feature_ID\"].isin(confirmed_ids)]\n",
    "\n",
    "# === Combine filtered data ===\n",
    "combined_df = pd.concat([filtered_pos, filtered_neg], ignore_index=True)\n",
    "\n",
    "# === Save to CSV ===\n",
    "combined_df.to_csv(\"NIAS_2b_Confirmed_Annotated.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(combined_df)} confirmed 2b matches to 'NIAS_2b_Confirmed_Annotated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668aefd-f56f-4f9c-be71-7c62c5a015e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load confirmed intensity data (from TraceFinder)\n",
    "area_df = pd.read_excel(\"NIAS_2b_IP_confirmed.xlsx\")\n",
    "area_df[\"ID\"] = area_df[\"ID\"].astype(str)  # Make sure ID is string\n",
    "\n",
    "# Load annotated matches\n",
    "annotated_df = pd.read_csv(\"NIAS_2b_Confirmed_Annotated.csv\", dtype=str)\n",
    "annotated_df[\"Feature_ID\"] = annotated_df[\"Feature_ID\"].astype(str)\n",
    "\n",
    "# Merge based on Feature_ID (from annotation) and ID (from quantification)\n",
    "merged_df = annotated_df.merge(area_df, how=\"left\", left_on=\"Feature_ID\", right_on=\"ID\")\n",
    "\n",
    "# Drop the duplicate 'ID' column if needed (same as Feature_ID)\n",
    "merged_df.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "# Save the complete file\n",
    "merged_df.to_csv(\"NIAS_2b_Confirmed_Annotated_With_areas.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Merged intensities for {len(merged_df)} confirmed 2b compounds.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
